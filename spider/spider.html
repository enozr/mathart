<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1, minimal-ui">
		<title>spider</title>
    <script type="text/javascript">
    var ua = navigator.userAgent.toLowerCase();
    var thishref = window.location.href;
   if (ua.indexOf('micromessenger') !== -1 && (thishref.indexOf('code') === -1)) {//微信中打开 且短网址 如不是从长网址回退
    thishref = window.encodeURI(thishref);
   // window.location.href = 'https://open.weixin.qq.com/connect/oauth2/authorize?appid=wx05125e8c1635642f&redirect_uri='+thishref+'?response_type=code&scope=snsapi_base&state=22&connect_redirect=1&from=timeline&isappinstalled=0#wechat_redirect';
}
    </script>
		<link rel="stylesheet" href="http://7i7ifh.com1.z0.glb.clouddn.com/github-markdown.css">
    <link rel="stylesheet" href=" http://cdn.bootcss.com/highlight.js/8.6/styles/github-gist.min.css">
		<style>
			body {
				min-width: 200px;
				max-width: 790px;
				margin: 0 auto;
				padding: 30px;
			}
		</style>
	</head>
	<body>
		<article class="markdown-body">
		<h1>爬虫</h1>
<h3>定义</h3>
<p>当我们需要数据的时候，整个互联网都是我们的数据库，某种意义上，我国最著名的爬虫应用就是百度，为了让你输入的关键词匹配万千网页，百度首先要抓取大量的网页数据，抓取数据处理一下并存起来，这个过程就是所谓的爬虫。</p>
<p>今日头条是另一个爬虫的案子，今日头条本身不做新闻，但自动爬取互联网上大量新闻，并按照自己的权重去打分，</p>
<p>什么是爬虫？爬虫相当于模拟浏览器去访问网站，然后把页面上的信息整理后放自己数据库里，不过这类爬虫虽然广泛强大，但是不很精密，我们做的则是所谓定向爬虫，有针对性地访问一些网站，量身定制，一个字段一个字段地搜集，时刻保持数据准确。</p>
<p>这几个月的经验而言，做爬虫大致有几个思路:</p>
<p>根据网址自拟规则，比如某个网址 <code>www.a.com/00001.html</code>, 猜测 <code>www.a.com/00002.html</code> 也是有的，总结一二，通过程序自动生成一堆网址，最后一一访问。</p>
<p>但也有可能，这个规律不怎么明显，比如你要爬取一个博客所有的文章，每个文章的url都很难推测，但是间接的，网站的列表页规律简单，<code>blog.a.com/page1.html</code>, <code>blog.a.com/page2.html</code>… 每个列表页上一堆超级链接，顺藤摸瓜就是文章页，那你可以通过遍历这个列表页得到所有文章的超级链接，然后爬取这些文章。这种方法是很普遍的爬虫模型，很多爬虫库的模型据此设计。</p>
<p>以上2种，大多是基于解析网页进行爬取的，好比你用你的程序模拟了一个假的浏览器，载入网站代码后打开后，解析并生成网页，然后到对应的地方取得对应的参数后拼起来放到你的数据库里。但也有些网站古道心肠，做了些现成的http接口，你访问就给你整理好的数据，有些还特尼玛全面，遇到这些，我等虫农笑逐颜开。</p>
<p>真正实战，还需克服许多问题，比如，如果每次访问1000个网站，明显会很快，但带宽肯定过不了，很多连接都超时挂了，漏了数据偷鸡不成十八米，而挨个爬取，网速跟不上，又怎么设计个合理的爬取队列？而你总任务爬百万个链接，速度慢得几天都搞不定，任务结束的时候之前的页面都更新了，这如何解？又或者网站检测到你的ip一天访问千万次的，直接封杀，又咋办…</p>
<p>细不展开了，总有招可以解这些问题，但大多数网站今日没有那么高明，未必为这些细节提前大动干戈，程序先跑起来就好，能抓老鼠就是好猫。爬取大多网站比我想象容易不少，毕竟，对于网站，明枪易躲暗箭难防，漏洞总是会有的，特别是bat以外的各种网站。</p>

		</article>
	</body>
	<script type="text/javascript" src="http://cdn.bootcss.com/zepto/1.1.6/zepto.min.js"></script>
	<script type="text/javascript" src="http://res.wx.qq.com/open/js/jweixin-1.0.0.js"></script>
  <script src="http://cdn.bootcss.com/highlight.js/8.0/highlight.min.js"></script>  
	<script type="text/javascript">

  hljs.initHighlightingOnLoad();

  var jsTicketUrl = encodeURIComponent(window.location.origin + window.location.pathname + window.location.search);
  $.getJSON('http://hotu.co/hotu-api/api/weixin/sign?url=' + jsTicketUrl,
    function(data, status) {
      data = data || {};
      var config = data.config;
      config.debug = false;
      wx.config(config);
      genShare();
    });

function genShare() {
  wx.ready(function() {
    var title = 'spider';
    var picUrl = 'http://7i7ifh.com1.z0.glb.clouddn.com/8f2281a623e8a03.jpg';
    var desc = '美的数学世界|' + 'spider' + '\n设计师的代码修炼之路';
    var shareUrl = 'https://open.weixin.qq.com/connect/oauth2/authorize?appid=wx05125e8c1635642f&redirect_uri=http://hotu.co/blog/spider/spider.html?response_type=code&scope=snsapi_base&state=22&connect_redirect=1&from=timeline&isappinstalled=0#wechat_redirect';
    var shareObj = {
      title: title,
      link: shareUrl,
      imgUrl: picUrl,
      desc: desc,
      success: function() {
      },
      cancel: function() {
      }
    };

    wx.onMenuShareTimeline(shareObj);
    wx.onMenuShareAppMessage(shareObj);
  });
};
	</script>
</html>
